################################################################################
# Copyright (c) 2020-2021, National Research Foundation (SARAO)
#
# Licensed under the BSD 3-Clause License (the "License"); you may not use
# this file except in compliance with the License. You may obtain a copy
# of the License at
#
#   https://opensource.org/licenses/BSD-3-Clause
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
################################################################################

"""Classes which handle movement of data around the system.

Asynchronous coordination between getting data from system RAM to the GPU (or
directly from the NIC to the GPU in the GPU-direct case) is handled here.
Processing by the GPU is scheduled, and an event-based synchronisation mechanism
to manage copies at the right time. Getting the processed data back from the GPU
ultimately to the NIC is also handled.
"""

import asyncio
import functools
import logging
import time
from collections import deque
from typing import Deque, Iterable, List, Optional, Sequence, cast

import numpy as np
import spead2.recv
from aiokatcp import Sensor, SensorSet
from katsdpsigproc import accel
from katsdpsigproc.abc import AbstractCommandQueue, AbstractContext, AbstractEvent
from katsdpsigproc.resource import async_wait_for_events

from .. import N_POLS
from ..monitor import Monitor
from . import BYTE_BITS, recv, send
from .compute import Compute
from .delay import AbstractDelayModel

logger = logging.getLogger(__name__)


def _device_allocate_slot(context: AbstractContext, slot: accel.IOSlot) -> accel.DeviceArray:
    return accel.DeviceArray(context, slot.shape, slot.dtype, slot.required_padded_shape())


def _host_allocate_slot(context: AbstractContext, slot: accel.IOSlot) -> accel.HostArray:
    return accel.HostArray(slot.shape, slot.dtype, slot.required_padded_shape(), context=context)


class BaseItem:
    """Base item for use in the input and output queues.

    .. rubric:: TODO

    - Can probably be combined with :class:`EventItem` since nothing else but
      that inherits from this.

    Parameters
    ----------
    timestamp
        Timestamp of the item.
    """

    timestamp: int

    def __init__(self, timestamp: int = 0) -> None:
        self.reset(timestamp)

    def reset(self, timestamp: int = 0) -> None:
        """Reset the item's timestamp to the provided desired timestamp."""
        self.timestamp = timestamp


class EventItem(BaseItem):
    """Queue Item for use in synchronisation between command queues.

    Derived classes will have allocated memory regions associated with them,
    appropriately sized for input or output data. Actions (whether kernel
    executions or copies to or from the device) for these memory regions are
    initiated, and then an event marker is added to the list in some variation
    of this manner:

    .. code-block:: python

        my_item.events.append(command_queue.enqueue_marker())

    The item can then be passed through a queue to the next stage in the
    program, which waits for the operations to be complete using
    :func:`enqueue_wait()`. This indicates that the operation is complete and
    the next thing can be done with whatever data is in that region of memory.

    Attributes
    ----------
    events
        A list of GPU event markers generated by an
        :class:`~katsdpsigproc.abc.AbstractCommandQueue`.
    """

    events: List[AbstractEvent]

    def enqueue_wait(self, command_queue: AbstractCommandQueue) -> None:
        """Block execution until all of this item's events are finished.

        If the events have already passed, then the function will return
        immediately; if not, execution will pause until they are all reached.
        """
        command_queue.enqueue_wait_for_events(self.events)

    def reset(self, timestamp: int = 0) -> None:
        """Reset the item's timestamp, and empty the event list."""
        super().reset(timestamp)
        self.events = []


class InItem(EventItem):
    """Item for use in input queues.

    This Item references GPU memory regions for input samples from both
    polarisations, with metadata describing their dimensions (number of samples
    and bitwidth of samples) in addition to the features of :class:`EventItem`.

    An example of usage is as follows:

    .. code-block:: python

        # In the receive function
        my_in_item.samples[pol].set_region(...)  # start copying sample data to the GPU,
        my_in_item.events.append(command_queue.enqueue_marker())
        in_queue.put_nowait(my_in_item)
        ...
        # in the processing function
        next_in_item = await self.in_queue.get() # get the item from the queue
        next_in_item.enqueue_wait(command_queue) # wait for its data to be completely copied
        ... # carry on executing kernels or whatever needs to be done with the data

    Attributes
    ----------
    samples
        A pair of device memory regions for storing the set of samples
        associated with each respective polarisation.
    chunks
        Chunks to return to recv after processing (used with gdrcopy only).
    n_samples
        Number of samples in each :class:`~katsdpsigproc.accel.DeviceArray` in
        :attr:`samples`.
    sample_bits
        Bitwidth of the data in :attr:`samples`.

    Parameters
    ----------
    compute
        F-engine Operation Sequence detailing the computation operations which
        will take place on the data in :attr:`samples`.
    timestamp
        Timestamp of the oldest digitiser sample represented in the data.
    use_gdrcopy
        Use GPU Direct. Defaults to False, because this only works on
        datacenter-grade cards.
    """

    samples: List[accel.DeviceArray]
    chunks: List[recv.Chunk]  # Used with gdrcopy only.
    n_samples: int
    sample_bits: int

    def __init__(self, compute: Compute, timestamp: int = 0, use_gdrcopy: bool = False) -> None:
        self.sample_bits = compute.sample_bits
        if use_gdrcopy:
            # Memory belongs to the chunks, and we set samples when
            # initialising the item from the chunks.
            self.samples = []
        else:
            self.samples = [
                _device_allocate_slot(compute.template.context, cast(accel.IOSlot, compute.slots[f"in{pol}"]))
                for pol in range(N_POLS)
            ]
        self.chunks = []
        super().__init__(timestamp)

    def reset(self, timestamp: int = 0) -> None:
        """Reset the item.

        Zero the timestamp, empty the event list and set number of samples to
        zero.
        """
        super().reset(timestamp)
        self.n_samples = 0

    @property
    def capacity(self) -> int:  # noqa: D401
        """Memory capacity in samples.

        The amount of space allocated to each polarisation stored in
        :attr:`samples`.
        """
        return self.samples[0].shape[0] * BYTE_BITS // self.sample_bits

    @property
    def end_timestamp(self) -> int:  # noqa: D401
        """End (i.e. latest) timestamp of the item."""
        return self.timestamp + self.n_samples


class OutItem(EventItem):
    """Item for use in output queues.

    This Item references GPU memory regions for output spectra from both
    polarisations, with something about the fine delay, in addition to the
    features of :class:`EventItem`.

    An example of usage is as follows:

    .. code-block:: python

        # In the processing function
        compute.run_some_dsp(my_out_item.spectra) # Run the DSP, whatever it is.
        my_out_item.events.append(command_queue.enqueue_marker())
        out_queue.put_nowait(my_out_item)
        ...
        # in the transmit function
        next_out_item = await self.out_queue.get() # get the item from the queue
        next_out_item.enqueue_wait(download_queue) # wait for event indicating DSP is finished
        next_out_item.get_async(download_queue) # Start copying data back to the host
        ... # Normally you'd put a marker on the queue again so that you know when the
            # copy is finished, but this needn't be attached to the item unless
            # there's another queue afterwards.

    Attributes
    ----------
    spectra
        This is the actual output data, a collection of spectra, arranged in
        memory by pol and by heap.
    fine_delay
        Provides a scratch space for collecting per-spectrum fine delays while
        the `OutItem` is being prepared. When the `OutItem` is placed onto the
        queue it is copied to the `Compute`.
    phase
        A similar scratch space for collecting per-spectrum phase offsets while
        the :class:`OutItem` is being prepared.
    n_spectra
        Number of spectra contained in :attr:`spectra`.

    Parameters
    ----------
    compute
        F-engine Operation Sequence detailing the DSP happening on the data,
        including details for buffers, context, shapes, slots, etc.
    timestamp
        Timestamp of the first spectrum in the `OutItem`.
    """

    spectra: accel.DeviceArray
    fine_delay: accel.HostArray
    phase: accel.HostArray
    n_spectra: int

    def __init__(self, compute: Compute, timestamp: int = 0) -> None:
        self.spectra = _device_allocate_slot(compute.template.context, cast(accel.IOSlot, compute.slots["out"]))
        self.fine_delay = _host_allocate_slot(compute.template.context, cast(accel.IOSlot, compute.slots["fine_delay"]))
        self.phase = _host_allocate_slot(compute.template.context, cast(accel.IOSlot, compute.slots["phase"]))
        super().__init__(timestamp)

    def reset(self, timestamp: int = 0) -> None:
        """Reset the item.

        Zero the item's timestamp, empty the event list and set number of
        spectra to zero.
        """
        super().reset(timestamp)
        self.n_spectra = 0

    @property
    def end_timestamp(self) -> int:  # noqa: D401
        """Past-the-end timestamp of the item.

        Following Python's normal exclusive-end convention.
        """
        return self.timestamp + self.n_spectra * 2 * self.channels

    @property
    def channels(self) -> int:  # noqa: D401
        """Number of channels."""
        return self.spectra.shape[1]

    @property
    def capacity(self) -> int:  # noqa: D401
        """Number of spectra stored in memory for each polarisation."""
        # PostProc's __init__ method gives this as (spectra // spectra_per_heap)*(spectra_per_heap), so
        # basically, the number of spectra.
        return self.spectra.shape[0] * self.spectra.shape[2]

    @property
    def pols(self) -> int:  # noqa: D401
        """Number of polarisations."""
        return self.spectra.shape[3]


class Processor:
    """Controls the bulk of the moving of data around the computer.

    The Processor creates input and output :class:`~katgpucbf.monitor.Queue`
    objects as well as a few :class:`InItem` and :class:`OutItem` objects to use
    on them. The actual Items (and the memory associated) are then continuously
    re-used because the allocation of memory is expensive. The data buffers are
    simply overwritten whenever they are used.

    :attr:`in_queue` and :attr:`in_free_queue` recycle the InItems, and
    similarly, :attr:`out_queue` and :attr:`out_free_queue` recycle the
    OutItems.

    The command queues for scheduling data copy tasks to/from the GPU are also
    managed by the Processor. The Events contained by the Items are the link
    between these two kinds of queues.

    .. todo::

      There is also a command_queue in the Engine class; it may be better to
      consolidate these.

    Attributes
    ----------
    in_queue
        Ready :class:`InItem` objects for processing on the GPU.
    in_free_queue
        Available :class:`InItem` objects for overwriting.
    out_queue
        Ready :class:`OutItem` objects for transmitting on the network.
    out_free_queue
        Available :class:`OutItem` objects for overwriting.

    Parameters
    ----------
    compute
        :class:`OperationSequence` containing all the steps for carrying out the
        F-engine's processing.
    delay_models
        The delay models which should be applied to the data.
    use_gdrcopy
        Assemble chunks directly in GPU memory (requires supported GPU).
    monitor
        Monitor object to use for generating the :class:`~asyncio.Queue` objects
        and reporting their events.
    sensors
        The set of sensors from the parent :class:`~katgpucbf.fgpu.Engine` object,
        currently needed for passing the dropped packet sensor down to the
        receiver for updating.
    """

    def __init__(
        self,
        compute: Compute,
        delay_models: Sequence[AbstractDelayModel],
        use_gdrcopy: bool,
        monitor: Monitor,
        sensors: Optional[SensorSet],
    ) -> None:
        self.compute = compute
        self.delay_models = delay_models
        n_in = 3
        n_out = 2
        n_send = 4

        # TODO test whether Python 3.8 allows for moving these type hints to the
        # normal place. asyncio.Queue doesn't support indexing, and this broke
        # things in 3.6, but 3.8 may have fixed it.
        self.in_queue = monitor.make_queue("in_queue", n_in)  # type: asyncio.Queue[Optional[InItem]]
        self.in_free_queue = monitor.make_queue("in_free_queue", n_in)  # type: asyncio.Queue[InItem]
        self.out_queue = monitor.make_queue("out_queue", n_out)  # type: asyncio.Queue[Optional[OutItem]]
        self.out_free_queue = monitor.make_queue("out_free_queue", n_out)  # type: asyncio.Queue[OutItem]
        self.send_free_queue = monitor.make_queue("send_free_queue", n_send)  # type: asyncio.Queue[send.Chunk]

        self.sensors = sensors
        self.monitor = monitor
        self._spectra = []
        for _ in range(n_in):
            self.in_free_queue.put_nowait(InItem(compute, use_gdrcopy=use_gdrcopy))
        for _ in range(n_out):
            item = OutItem(compute)
            self._spectra.append(item.spectra)
            self.out_free_queue.put_nowait(item)
        self._in_items: Deque[InItem] = deque()
        self._out_item = self.out_free_queue.get_nowait()
        self._upload_queue = compute.template.context.create_command_queue()
        self._download_queue = compute.template.context.create_command_queue()
        self._use_gdrcopy = use_gdrcopy

    @property
    def channels(self) -> int:  # noqa: D401
        """Number of channels into which the incoming signal is decomposed."""
        return self.compute.channels

    @property
    def taps(self) -> int:  # noqa: D401
        """Number of taps in the PFB-FIR filter."""
        return self.compute.template.taps

    @property
    def spectra_per_heap(self) -> int:  # noqa: D401
        """The number of spectra which will be transmitted per output heap."""
        return self.compute.spectra_per_heap

    @property
    def sample_bits(self) -> int:  # noqa: D401
        """Bitwidth of the incoming digitiser samples."""
        return self.compute.sample_bits

    @property
    def spectra_samples(self) -> int:  # noqa: D401
        """Number of incoming digitiser samples needed per spectrum."""
        return 2 * self.channels

    @property
    def pols(self) -> int:  # noqa: D401
        """Number of polarisations."""
        return N_POLS

    @property
    def peerdirect_memory_regions(self) -> Sequence[object]:  # noqa D102
        """GPU memory regions for direct network transmission.

        Python buffer objects encapsulating GPU memory that will be transmitted
        to the network directly, without copying to the CPU."""
        return [spectra.buffer.gpudata.as_buffer(spectra.buffer.nbytes) for spectra in self._spectra]

    async def _next_in(self) -> Optional[InItem]:
        """Load next InItem for processing.

        Move the next :class:`InItem` from the `in_queue` to `_in_items`, where
        it will be picked up by the processing.
        """
        with self.monitor.with_state("run_processing", "wait in_queue"):
            item = await self.in_queue.get()

        if item is not None:
            self._in_items.append(item)
            # print(f'Received input with timestamp {self._in_items[-1].timestamp}, '
            #       f'{self._in_items[-1].n_samples} samples')

            # Make sure that all events associated with the item are past.
            self._in_items[-1].enqueue_wait(self.compute.command_queue)
        else:
            # To keep run_processing simple, it may make further calls to
            # _next_in after receiving a None. To keep things simple, put
            # a None back into the queue so that the next call also gets
            # None rather than hanging.
            self.in_queue.put_nowait(None)
        return item

    async def _fill_in(self) -> bool:
        """Load sufficient InItems to continue processing.

        Tries to get at least two items into ``self._in_items``, and if
        loading a second item that is adjacent to the first, copies the overlap
        region.

        Returns true if processing can proceed, false if the stream is
        exhausted.
        """
        if len(self._in_items) == 0:
            if not (await self._next_in()):
                return False
        if len(self._in_items) == 1 and (await self._next_in()):
            # Copy the head of the new chunk to the tail of the older chunk
            # to allow for PFB windows to fit and for some protection against
            # sharp changes in delay.
            #
            # This could only fail if we'd lost a whole input chunk of
            # data from the digitiser. In that case the data we'd like
            # to copy is missing so we can't do this step.
            # TODO: Currently fgpu doesn't have much (really any)
            # handling for missing data.
            if self._in_items[0].end_timestamp == self._in_items[1].timestamp:
                sample_bits = self._in_items[0].sample_bits
                copy_samples = self._in_items[0].capacity - self._in_items[0].n_samples
                copy_bytes = copy_samples * sample_bits // BYTE_BITS
                for pol in range(len(self._in_items[0].samples)):
                    self._in_items[1].samples[pol].copy_region(
                        self.compute.command_queue,
                        self._in_items[0].samples[pol],
                        np.s_[:copy_bytes],
                        np.s_[-copy_bytes:],
                    )
                self._in_items[0].n_samples += copy_samples
        return True

    def _pop_in(self, streams: List[spead2.recv.ChunkRingStream]) -> None:
        """Remove the oldest InItem."""
        item = self._in_items.popleft()
        event = self.compute.command_queue.enqueue_marker()
        if self._use_gdrcopy:
            item.samples = []
            chunks = item.chunks
            item.chunks = []
            asyncio.create_task(self._push_chunks(streams, chunks, event))
        else:
            item.events.append(event)
        self.in_free_queue.put_nowait(item)

    async def _next_out(self, new_timestamp: int) -> OutItem:
        """Grab the next free OutItem in the queue."""
        with self.monitor.with_state("run_processing", "wait out_free_queue"):
            item = await self.out_free_queue.get()

        # Just make double-sure that all events associated with the item are past.
        item.enqueue_wait(self.compute.command_queue)
        item.reset(new_timestamp)
        return item

    async def _flush_out(self, new_timestamp: int) -> None:
        """Start the backend processing and prepare the data for transmission.

        Kick off the `run_backend()` processing, and put an event on the
        relevant command queue. This lets the next coroutine (run_transmit) know
        that the backend processing is finished, and the data can be transmitted
        out.

        Parameters
        ----------
        new_timestamp
            The timestamp that will immediately follow the current OutItem.
        """
        # Round down to a multiple of accs (don't send heap with partial
        # data).
        accs = self._out_item.n_spectra // self.spectra_per_heap
        self._out_item.n_spectra = accs * self.spectra_per_heap
        if self._out_item.n_spectra > 0:
            # TODO: only need to copy the relevant region, and can limit
            # postprocessing to the relevant range (the FFT size is baked into
            # the plan, so is harder to modify on the fly).
            self.compute.buffer("fine_delay").set_async(self.compute.command_queue, self._out_item.fine_delay)
            self.compute.buffer("phase").set_async(self.compute.command_queue, self._out_item.phase)
            self.compute.run_backend(self._out_item.spectra)
            self._out_item.events.append(self.compute.command_queue.enqueue_marker())
            self.out_queue.put_nowait(self._out_item)
            # TODO: could set it to None, since we only need it when we're
            # ready to flush again?
            self._out_item = await self._next_out(new_timestamp)
        else:
            self._out_item.timestamp = new_timestamp

    @staticmethod
    async def _push_chunks(
        streams: Iterable[spead2.recv.ChunkRingStream], chunks: Iterable[recv.Chunk], event: AbstractEvent
    ) -> None:
        """Return chunks to the streams once `event` has fired.

        This is only used when using gdrcopy.
        """
        await async_wait_for_events([event])
        for stream, chunk in zip(streams, chunks):
            stream.add_free_chunk(chunk)

    async def run_processing(self, streams: List[spead2.recv.ChunkRingStream]) -> None:
        """Do the hard work of the F-engine.

        This function takes place entirely on the GPU. First, a little bit of
        the next chunk is copied to the end of the previous one, to allow for
        the overlap required by the PFB. Some coarse delay happens (though this
        is incomplete) and the PFB-FIR is run. Then a batch FFT operation is
        applied, and finally, fine-delay (currently just a place-holder),
        quantisation and corner-turn are performed.

        Parameters
        ----------
        streams
            These only seem to be used in the _use_gdrcopy case.
        """
        while await self._fill_in():
            # If the input starts too late for the next expected timestamp,
            # we need to skip ahead to the next heap after the start, and
            # flush what we already have.
            timestamp = self._out_item.end_timestamp
            orig_timestamp, _fine_delay, _phase = self.delay_models[0].invert(timestamp)
            if orig_timestamp < self._in_items[0].timestamp:
                align = self.spectra_per_heap * self.spectra_samples
                timestamp = max(timestamp, self._in_items[0].timestamp)
                timestamp = accel.roundup(timestamp, align)
                # TODO: add a helper to the delay model to accelerate this?
                # Might not be needed, since max delay is not many multiples of
                # align.
                while True:
                    orig_timestamp, _fine_delay, _phase = self.delay_models[0].invert(timestamp)
                    if orig_timestamp >= self._in_items[0].timestamp:
                        break
                    timestamp += align
                await self._flush_out(timestamp)
            assert timestamp == self._out_item.end_timestamp

            # This block does some basic coarse delay.
            # `orig_timestamp` is the timestamp of first sample from the input
            # to process in the PFB to produce the output spectrum with
            # `timestamp`. `offset` is the sample index corresponding to
            # `orig_timestamp` within the InItem.
            coarse_delay = timestamp - orig_timestamp
            offset = orig_timestamp - self._in_items[0].timestamp

            # Identify a block of frontend work. We can grow it until
            # - we run out of the current input array;
            # - we fill up the output array; or
            # - the coarse delay changes;
            # We speculatively calculate delays until one of the first two is
            # met, then truncate if we observe a coarse delay change.
            max_end_in = self._in_items[0].end_timestamp - self.taps * self.spectra_samples + 1
            max_end_out = self._out_item.timestamp + self._out_item.capacity * self.spectra_samples
            max_end = min(max_end_in, max_end_out)
            # Speculatively evaluate until one of the first two conditions is met
            timestamps = np.arange(timestamp, max_end, self.spectra_samples)
            orig_timestamps, fine_delays, phase = self.delay_models[0].invert_range(
                timestamp, max_end, self.spectra_samples
            )
            coarse_delays = timestamps - orig_timestamps
            # Uses fact that argmax returns first maximum i.e. first true value
            delay_change = int(np.argmax(coarse_delays != coarse_delay))
            if coarse_delays[delay_change] != coarse_delay:
                logger.debug(
                    "Coarse delay changed from %d to %d at %d",
                    coarse_delay,
                    coarse_delays[delay_change],
                    orig_timestamps[delay_change],
                )
                orig_timestamps = orig_timestamps[:delay_change]
                fine_delays = fine_delays[:delay_change]
                phase = phase[:delay_change]
                batch_spectra = delay_change
            else:
                batch_spectra = len(orig_timestamps)

            # Here we run the "frontend" which handles:
            # - 10-bit to float conversion
            # - Coarse delay
            # - The PFB-FIR.
            if batch_spectra > 0:
                logging.debug("Processing %d spectra", batch_spectra)
                # TODO: here we're just duplicating the fine delay and phase
                # across the polarisations. We should actually use separate
                # delay models.
                self._out_item.fine_delay[
                    self._out_item.n_spectra : self._out_item.n_spectra + batch_spectra
                ] = fine_delays[:, np.newaxis]
                # Divide by pi because the arguments of sincospif() used in the
                # kernel are in radians/PI.
                self._out_item.phase[self._out_item.n_spectra : self._out_item.n_spectra + batch_spectra] = (
                    phase[:, np.newaxis] / np.pi
                )
                self.compute.run_frontend(self._in_items[0].samples, offset, self._out_item.n_spectra, batch_spectra)
                self._out_item.n_spectra += batch_spectra

            # The _flush_out method calls the "backend" which triggers the FFT
            # and postproc operations.
            end_timestamp = self._out_item.end_timestamp
            if end_timestamp >= max_end_out:
                # We've filled up the output buffer.
                await self._flush_out(end_timestamp)

            if end_timestamp >= max_end_in:
                # We've exhausted the input buffer.
                # TODO: should maybe also do this if _in_items[1] would work
                # just as well and we've filled the output buffer.
                self._pop_in(streams)
        await self._flush_out(0)  # Timestamp doesn't matter since we're finished
        logger.debug("run_processing completed")
        self.out_queue.put_nowait(None)

    async def run_receive(self, streams: List[spead2.recv.ChunkRingStream], layout: recv.Layout) -> None:
        """Receive data from the network, queue it up for processing.

        This function receives chunk sets, which are chunks in groups of two -
        one per polarisation, from the spead2 receiver streams given. For each
        chunk set received, copies of the data to the GPU are initiated,
        awaited, and then the chunk containers are returned to the receiver
        stream so that the memory need not be expensively re-allocated every
        time.

        In the GPU-direct case, <TODO clarify once I understand better>.

        Parameters
        ----------
        streams
            There should be only two of these because they each represent one of
            the digitiser's two polarisations.
        """
        async for chunks in recv.chunk_sets(streams, layout, self.monitor, self.sensors):
            with self.monitor.with_state("run_receive", "wait in_free_queue"):
                in_item = await self.in_free_queue.get()
            with self.monitor.with_state("run_receive", "wait events"):
                # Make sure all the item's events are past.
                await async_wait_for_events(in_item.events)
            in_item.reset(chunks[0].timestamp)

            # In steady-state, chunks should be the same size, but during
            # shutdown, the last chunk may be short.
            in_item.n_samples = chunks[0].data.nbytes * BYTE_BITS // self.sample_bits

            transfer_events = []
            if self._use_gdrcopy:
                assert len(in_item.samples) == 0
                in_item.samples = [chunk.device for chunk in chunks]  # type: ignore
                in_item.chunks = chunks
                self.in_queue.put_nowait(in_item)
            else:
                # Copy each pol chunk to the right place on the GPU.
                for pol, chunk in enumerate(chunks):
                    in_item.samples[pol].set_region(
                        self._upload_queue, chunk.data, np.s_[: chunk.data.nbytes], np.s_[:], blocking=False
                    )
                    transfer_events.append(self._upload_queue.enqueue_marker())

                # Put events on the queue so that run_processing() knows when to
                # start.
                in_item.events.extend(transfer_events)
                self.in_queue.put_nowait(in_item)

                # Wait until the copy is done, and then give the chunks of memory
                # back to the receiver streams for reuse.
                for pol in range(len(chunks)):
                    with self.monitor.with_state("run_receive", "wait transfer"):
                        await async_wait_for_events([transfer_events[pol]])
                    streams[pol].add_free_chunk(chunks[pol])
        logger.debug("run_receive completed")
        self.in_queue.put_nowait(None)

    def _chunk_finished(self, chunk: send.Chunk, n_heaps: int, n_bytes: int, future: asyncio.Future) -> None:
        """Return a chunk to the free queue after it has completed transmission.

        This is intended to be used as a callback on an :class:`asyncio.Future`.
        """
        self.send_free_queue.put_nowait(chunk)
        try:
            future.result()  # No result, but want the exception
        except asyncio.CancelledError:
            return
        except Exception:
            logger.exception("Error sending chunk")
            return

        if self.sensors is not None:
            # Get a common timestamp for all the updates
            sensor_timestamp = time.time()

            def increment(sensor: Sensor, incr: int):
                sensor.set_value(sensor.value + incr, timestamp=sensor_timestamp)

            increment(self.sensors["output-heaps-total"], n_heaps)
            # out_item.spectra.shape[1:] is the shape of each frame
            increment(self.sensors["output-bytes-total"], n_bytes)

    async def run_transmit(self, stream: "spead2.send.asyncio.AsyncStream") -> None:
        """Get the processed data from the GPU to the Network.

        This could be done either with or without GPUDirect. In the
        non-GPUDirect case, :class:`OutItem` objects are pulled from the
        `out_queue`. We wait for the events that mark the end of the processing,
        then copy the data to host memory before turning it over to the
        :obj:`sender` for transmission on the network. The "empty" item is then
        returned to :func:`run_processing` via the `out_free_queue`.

        In the GPUDirect case, <TODO clarify once I understand better>.

        Parameters
        ----------
        sender
            This object, written in C++, takes large chunks of data and packages
            it appropriately in SPEAD heaps for transmission on the network.
        """
        task: Optional[asyncio.Future] = None
        while True:
            with self.monitor.with_state("run_transmit", "wait out_queue"):
                out_item = await self.out_queue.get()
            if not out_item:
                break
            with self.monitor.with_state("run_transmit", "wait send_free_queue"):
                chunk = await self.send_free_queue.get()
            # TODO: use get_region since it might be partial
            if chunk.device:
                old_spectra = chunk.device
                chunk.device = out_item.spectra
                # TODO: this will need to be reworked after conversion of sending to Python
                chunk.data = chunk.device.buffer.gpudata.as_buffer(chunk.device.buffer.nbytes)
                out_item.spectra = old_spectra
                events = out_item.events
            else:
                self._download_queue.enqueue_wait_for_events(out_item.events)
                assert isinstance(chunk.data, accel.HostArray)
                out_item.spectra.get_async(self._download_queue, chunk.data)
                events = [self._download_queue.enqueue_marker()]
            chunk.timestamp = out_item.timestamp
            with self.monitor.with_state("run_transmit", "wait transfer"):
                await async_wait_for_events(events)
            n_frames = out_item.n_spectra // self.spectra_per_heap
            n_bytes = n_frames * np.product(out_item.spectra.shape[1:]) * out_item.spectra.dtype.itemsize
            n_heaps = n_frames * stream.num_substreams
            out_item.reset()
            self.out_free_queue.put_nowait(out_item)
            task = asyncio.create_task(chunk.send(stream, n_frames))
            task.add_done_callback(functools.partial(self._chunk_finished, chunk, n_heaps, n_bytes))

        if task:
            try:
                await task
            except Exception:
                pass  # It's already logged by the chunk_finished callback
        stop_heap = spead2.send.Heap(send.FLAVOUR)
        stop_heap.add_end()
        for substream_index in range(stream.num_substreams):
            await stream.async_send_heap(stop_heap, substream_index=substream_index)
        logger.debug("run_transmit completed")
